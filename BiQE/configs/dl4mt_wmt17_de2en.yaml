data_configs:
  lang_pair: "de-en"
  train_data:
    - "/home/user_data/houq/wmt17_de_en/train.tok.tc.bpe.90000.de"
    - "/home/user_data/houq/wmt17_de_en/train.tok.tc.bpe.90000.en"
  valid_data:
    - "/home/user_data/houq/wmt17_de_en/dev.tok.tc.bpe.90000.de"
    - "/home/user_data/houq/wmt17_de_en/dev.tok.tc.bpe.90000.en"
  bleu_valid_reference: "/home/user_data/houq/wmt17_de_en/dev/newstest2016.tc.en"
  vocabularies:
    - type: "bpe"
      dict_path: "/home/user_data/houq/wmt17_de_en/vocab.de.json"
      max_n_words: -1
    - type: "bpe"
      dict_path: "/home/user_data/houq/wmt17_de_en/vocab.en.json"
      max_n_words: -1
  max_len:
    - 100
    - 100
  num_refs: 1
  eval_at_char_level: false

model_configs:
  model: DL4MT
  d_word_vec: 512
  d_model: 512
  dropout: 0.1
  proj_share_weight: false
  bridge_type: "mlp"

optimizer_configs:
  optimizer: "adam"
  learning_rate: 0.2
  grad_clip: -1.0
  optimizer_params: ~
  schedule_method: noam
  scheduler_configs:
    d_model: 512
    warmup_steps: 8000

training_configs:
  seed: 1234
  max_epochs: 50
  shuffle: true
  use_bucket: true
  batch_size: 1250
  batching_key: "tokens"
  update_cycle: 20
  valid_batch_size: 20
  disp_freq: 500
  save_freq: 500
  num_kept_checkpoints: 1
  loss_valid_freq: 500
  bleu_valid_freq: 500
  bleu_valid_batch_size: 20
  bleu_valid_warmup: 1
  bleu_valid_configs:
    max_steps: 150
    beam_size: 4
    alpha: 0.6
    postprocess: True
  early_stop_patience: 50